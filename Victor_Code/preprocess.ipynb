{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all paths for both the image and the label files of the training dataset\n",
    "from glob import glob\n",
    "base_path = '../raw_custom_data/AWS_AI_Preliminary_Contest/data'\n",
    "\n",
    "types = ('png', 'jpg') # the tuple of file types\n",
    "imgs = []\n",
    "for t in types:\n",
    "    imgs.extend(glob(base_path + '/*/*/*/*.{}'.format(t)))\n",
    "\n",
    "xmls = glob(base_path + '/*/*/*/*.xml')\n",
    "\n",
    "# assert len(imgs) == len(xmls),\"dataset issue: # of images = {} , and # of xml files = {}\".format(len(imgs),len(xmls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of classes for YOLOv3 training\n",
    "classes = {}\n",
    "with open('../data/custom/classes.names','r') as f:\n",
    "    for cnt, line in enumerate(f):\n",
    "#         print(line)\n",
    "        classes[line.strip()] = cnt\n",
    "# classes['4710105030326']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util function for corresponding the image with the label by\n",
    "# getting the path of the label xml file according to the path of the image file\n",
    "\n",
    "import os\n",
    "\n",
    "def get_xml_from_image(img_path):\n",
    "\n",
    "    p,f = os.path.split(img_path)\n",
    "    name,ext = f.split('.')\n",
    "    return os.path.join(p, name + '.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29827/29827 [04:49<00:00, 102.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# After the Preparation\n",
    "# Do the actual work of renaming, converting, moving to the correct folders the image and label files\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "img_dest_path = '../data/custom/images'\n",
    "label_dest_path = '../data/custom/labels'\n",
    "\n",
    "for img in tqdm(imgs):\n",
    "    components = img.split('/')\n",
    "    count = len(components)\n",
    "    new_img_name = components[-4] + '_' + components[-3] + '_' + components[-2] + '_' + components[-1]\n",
    "    new_label_name = components[-4] + '_' + components[-3] + '_' + components[-2] + '_' + components[-1].split('.')[0] + '.txt'\n",
    "\n",
    "\n",
    "    label_idx = classes[components[-4]]\n",
    "    \n",
    "    shutil.copyfile(img,os.path.join(img_dest_path,new_img_name))\n",
    "\n",
    "    with open(os.path.join(label_dest_path,new_label_name), \"w+\") as text_file:\n",
    "        xml = get_xml_from_image(img)\n",
    "        with open(xml, 'r') as f:\n",
    "            text = f.read()\n",
    "#         print(\"text= \", text)\n",
    "        p_name = re.compile(\"<name>\\s*(.*)\\s*</name>\")\n",
    "        result = p_name.search(text)\n",
    "        name = result.group(1)\n",
    "\n",
    "        p_xmin = re.compile(\"<xmin>\\s*(.*)\\s*</xmin>\")\n",
    "        result = p_xmin.search(text)\n",
    "        xmin = result.group(1)\n",
    "\n",
    "        p_xmax = re.compile(\"<xmax>\\s*(.*)\\s*</xmax>\")\n",
    "        result = p_xmax.search(text)\n",
    "        xmax = result.group(1)\n",
    "\n",
    "        p_ymin = re.compile(\"<ymin>\\s*(.*)\\s*</ymin>\")\n",
    "        result = p_ymin.search(text)\n",
    "        ymin = result.group(1)\n",
    "\n",
    "        p_ymax = re.compile(\"<ymax>\\s*(.*)\\s*</ymax>\")\n",
    "        result = p_ymax.search(text)\n",
    "        ymax = result.group(1)\n",
    "\n",
    "        p_width = re.compile(\"<width>\\s*(.*)\\s*</width>\")\n",
    "        result = p_width.search(text)\n",
    "        img_width = result.group(1)\n",
    "\n",
    "        p_height = re.compile(\"<height>\\s*(.*)\\s*</height>\")\n",
    "        result = p_height.search(text)\n",
    "        img_height = result.group(1)\n",
    "\n",
    "        bottom = float(ymax) / float(img_height)\n",
    "        left = float(xmin) / float(img_width)\n",
    "        width = abs(float(xmax) - float(xmin)) / float(img_width)\n",
    "        height = abs(float(ymax) - float(ymin)) / float(img_height)\n",
    "        \n",
    "        out_line = '{} {:.9f} {:.9f} {:.9f} {:.9f}'.format(label_idx, left + (width / 2), bottom - (height / 2), width, height)\n",
    "#         print(out_line)\n",
    "        text_file.write(out_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_txt_from_image(img_path):\n",
    "\n",
    "    p,f = os.path.split(img_path)\n",
    "    name,ext = f.split('.')\n",
    "    b,t = os.path.split(p)\n",
    "    return os.path.join(b, 'labels', name + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and validation set\n",
    "split_ratio = 0.01\n",
    "SEED = 1256\n",
    "\n",
    "# Get the list of all image files\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "types = ('png', 'jpg') # the tuple of file types\n",
    "all_images = []\n",
    "for t in types:\n",
    "    all_images.extend(glob('../data/custom/images/*'))\n",
    "#shuffle images order\n",
    "import random\n",
    "\n",
    "# random.seed(SEED)\n",
    "random.shuffle(all_images)\n",
    "# Get the list of all label files, aranged by the order that correponds to that of the list of all images  \n",
    "all_labels = list(map(get_txt_from_image, all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/custom/images/748675116052_Camera3_6_21.png',\n",
       " '../data/custom/labels/748675116052_Camera3_6_21.txt')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idx = 11\n",
    "# all_images[idx],all_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train data:  59059\n",
      "number of validation data:  597\n"
     ]
    }
   ],
   "source": [
    "# write the train.txt file that defines the training dataset\n",
    "number_of_train_data = int(len(all_images)*(1 - split_ratio))\n",
    "print(\"number of train data: \", number_of_train_data)\n",
    "\n",
    "with open('../data/custom/train.txt','w+') as f:\n",
    "    for i in range(number_of_train_data):\n",
    "        image_str = all_images[i][3:] + '\\n'\n",
    "#         print(image_str)\n",
    "        f.write(image_str)\n",
    "\n",
    "# write the valid.txt file that defines the validation dataset\n",
    "\n",
    "number_of_valid_data = len(all_images) - number_of_train_data\n",
    "print(\"number of validation data: \", number_of_valid_data)\n",
    "\n",
    "with open('../data/custom/valid.txt','w+') as f:\n",
    "    for i in range(number_of_valid_data):\n",
    "        image_str = all_images[number_of_train_data + i][3:] + '\\n'\n",
    "#         print(image_str)\n",
    "        f.write(image_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
